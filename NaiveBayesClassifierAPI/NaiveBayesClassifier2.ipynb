{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6)Assuming a set of documents that need to be classified, use the naÃ¯ve Bayesian Classifier model to perform this task. Built-in Java classes/API can be used to write the program. Calculate the accuracy, precision, and recall for your data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Classification using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances in the dataset: 18\n",
      "\n",
      "The message and its label of first 5 instances are listed below\n",
      "I love this sandwich -> pos\n",
      "This is an amazing place -> pos\n",
      "I feel very good about these beers -> pos\n",
      "This is my best work -> pos\n",
      "What an awesome view -> pos\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "txt=pd.read_csv('Text.csv',names=['text','label']) #Tabular form data\n",
    "print('Total instances in the dataset:',txt.shape[0])\n",
    "txt['labelnum']=txt.label.map({'pos':1,'neg':0})\n",
    "X=txt.text\n",
    "Y=txt.labelnum\n",
    "print('\\nThe message and its label of first 5 instances are listed below')\n",
    "X5, Y5 = X[0:5], txt.label[0:5]\n",
    "for x, y in zip(X5,Y5):\n",
    "    print(x,'->',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset is split into Training and Testing samples\n",
      "Total training instances : 13\n",
      "Total testing instances : 5\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into train and test data\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,Y,random_state=0)\n",
    "print('\\nDataset is split into Training and Testing samples')\n",
    "print('Total training instances :', xtrain.shape[0])\n",
    "print('Total testing instances :', xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total features extracted using CountVectorizer: 50\n"
     ]
    }
   ],
   "source": [
    "# Output of count vectoriser is a sparse matrix\n",
    "# CountVectorizer - stands for 'feature extraction'\n",
    "count_vect = CountVectorizer()\n",
    "xtrain_dtm = count_vect.fit_transform(xtrain) # Transform training data into document-term matrix\n",
    "xtest_dtm = count_vect.transform(xtest)\n",
    "print('\\nTotal features extracted using CountVectorizer:',xtrain_dtm.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features for first 5 training instances are listed below\n",
      "    about  am  an  and  awesome  bad  beers  best  boss  can  ...   today  \\\n",
      "0       0   0   1    0        1    0      0     0     0    0  ...       0   \n",
      "1       1   0   0    0        0    0      1     0     0    0  ...       0   \n",
      "2       0   0   0    0        0    0      0     0     0    0  ...       0   \n",
      "3       0   0   0    0        0    0      0     0     0    0  ...       1   \n",
      "4       0   0   0    0        0    0      0     0     1    0  ...       0   \n",
      "5       0   0   0    0        0    0      0     0     0    1  ...       0   \n",
      "6       0   1   0    1        0    0      0     0     0    0  ...       0   \n",
      "7       0   0   0    0        0    0      0     0     0    0  ...       0   \n",
      "8       0   0   0    0        0    0      0     1     0    0  ...       0   \n",
      "9       0   0   0    0        0    0      0     0     0    0  ...       0   \n",
      "10      0   0   0    0        0    0      0     0     0    0  ...       0   \n",
      "11      0   0   0    0        0    1      0     0     0    0  ...       0   \n",
      "12      0   0   0    0        0    0      0     0     0    0  ...       0   \n",
      "\n",
      "    tomorrow  very  view  we  went  what  will  with  work  \n",
      "0          0     0     1   0     0     1     0     0     0  \n",
      "1          0     1     0   0     0     0     0     0     0  \n",
      "2          1     0     0   1     0     0     1     0     0  \n",
      "3          0     0     0   0     1     0     0     0     0  \n",
      "4          0     0     0   0     0     0     0     0     0  \n",
      "5          0     0     0   0     0     0     0     1     0  \n",
      "6          0     0     0   0     0     0     0     0     0  \n",
      "7          0     0     0   0     0     0     0     0     0  \n",
      "8          0     0     0   0     0     0     0     0     1  \n",
      "9          0     0     0   0     0     0     0     0     0  \n",
      "10         0     0     0   0     0     0     0     0     0  \n",
      "11         0     0     0   0     0     0     0     0     0  \n",
      "12         0     0     0   0     0     0     0     0     0  \n",
      "\n",
      "[13 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\nFeatures for first 5 training instances are listed below')\n",
    "df=pd.DataFrame(xtrain_dtm.toarray(),columns=count_vect.get_feature_names())\n",
    "#print(df[0:5])#tabular representation\n",
    "print(df)\n",
    "#print(xtrain_dtm) #Same as above but sparse matrix representation\n",
    "# Training Naive Bayes (NB) classifier on training data.\n",
    "clf = MultinomialNB().fit(xtrain_dtm,ytrain)\n",
    "predicted = clf.predict(xtest_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classstification results of testing samples are given below\n",
      "This is an amazing place -> neg \n",
      "I am tired of this stuff -> neg \n",
      "He is my sworn enemy -> neg \n",
      "This is an awesome place -> pos \n",
      "What a great holiday -> pos \n",
      "\n",
      "Accuracy metrics\n",
      "Accuracy of the classifer is 0.8\n",
      "Recall : 0.6666666666666666 \n",
      "Precison : 1.0\n",
      "Confusion matrix\n",
      "[[2 0]\n",
      " [1 2]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassstification results of testing samples are given below')\n",
    "for doc, p in zip(xtest, predicted):\n",
    "    pred = 'pos' if p==1 else 'neg'\n",
    "    print('%s -> %s ' % (doc, pred))\n",
    "#printing accuracy metrics\n",
    "print('\\nAccuracy metrics')\n",
    "print('Accuracy of the classifer is',metrics.accuracy_score(ytest,predicted))\n",
    "print('Recall :',metrics.recall_score(ytest,predicted),\n",
    "'\\nPrecison :',metrics.precision_score(ytest,predicted))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
